{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoNZfAOEutIvy4H+WPvin2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EliEli94/EliEli94/blob/main/idinfo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h11uxX4nwP_",
        "outputId": "b46178f2-7e5d-4f32-9790-59324b641db9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (3.0.10)\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-j6461hvt\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-j6461hvt\n",
            "  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools==2.0) (71.0.4)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.10/dist-packages (from pycocotools==2.0) (3.0.10)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools==2.0) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0) (1.16.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp310-cp310-linux_x86_64.whl size=375615 sha256=a9ef95ab9a42cfb9add3dcf97e2be6b79d32a71bc7bf2648c323372b0817ed2f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wb39nxyu/wheels/39/61/b4/480fbddb4d3d6bc34083e7397bc6f5d1381f79acc68e9f3511\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.8\n",
            "    Uninstalling pycocotools-2.0.8:\n",
            "      Successfully uninstalled pycocotools-2.0.8\n",
            "Successfully installed pycocotools-2.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "%%shell\n",
        "\n",
        "pip install cython\n",
        "# Install pycocotools, the version by default in Colab\n",
        "# has a bug fixed in https://github.com/cocodataset/cocoapi/pull/354\n",
        "pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "git clone https://github.com/MbassiJaphet/pytorch-for-information-extraction.git\n",
        "% cd pytorch-for-information-extraction/code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "rJnc_901nxjU",
        "outputId": "400f02d1-435e-475c-e9f2-7c24911454e7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-for-information-extraction'...\n",
            "remote: Enumerating objects: 1170, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 1170 (delta 6), reused 5 (delta 5), pack-reused 1150\u001b[K\n",
            "Receiving objects: 100% (1170/1170), 39.14 MiB | 29.62 MiB/s, done.\n",
            "Resolving deltas: 100% (556/556), done.\n",
            "/bin/bash: line 2: fg: no job control\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command 'git clone https://github.com/MbassiJaphet/pytorch-for-information-extraction.git\n% cd pytorch-for-information-extraction/code\n' returned non-zero exit status 1.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4ced0cf24236>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'git clone https://github.com/MbassiJaphet/pytorch-for-information-extraction.git\\n% cd pytorch-for-information-extraction/code\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m       raise subprocess.CalledProcessError(\n\u001b[0m\u001b[1;32m    138\u001b[0m           \u001b[0mreturncode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m       )\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'git clone https://github.com/MbassiJaphet/pytorch-for-information-extraction.git\n% cd pytorch-for-information-extraction/code\n' returned non-zero exit status 1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resolve imports for detection module\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import utils\n",
        "\n",
        "from PIL import Image, ImageDraw, ImageFilter\n",
        "#%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# define transforms to convert PIL image to torch.Tensor\n",
        "imgToTensor = torchvision.transforms.ToTensor()\n",
        "# define transforms to convert torch.Tensor to PIL image\n",
        "tensorToPIL = torchvision.transforms.ToPILImage()"
      ],
      "metadata": {
        "id": "PUFE2VQMn1_N"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DetectionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_path, mode=None, transforms=None):\n",
        "        self.mode = mode\n",
        "        self.data_path = data_path\n",
        "        self.transforms = transforms\n",
        "        # everything but our dataset classes ibelong to class 'BACKGROUND'\n",
        "        self.classes = ['BACKGROUND']\n",
        "        # loading our dataset classes names\n",
        "        _classes_names = utils.load_json(os.path.join(data_path, 'classes.json'))['classes']\n",
        "        # implicitly attributing index '0' to BACKGROUND class\n",
        "        self.classes.extend(_classes_names)\n",
        "        # load all image files\n",
        "        dataset_file = os.path.join(data_path, str(mode).lower().__add__('.json'))\n",
        "        if not os.path.exists(dataset_file):\n",
        "            raise Exception(\"Invalid Mode: '{}'\\n Available modes are: 'TRAIN', 'VALID', 'TEST'.\".format(mode))\n",
        "        data_dict = utils.load_json(dataset_file)\n",
        "        self.image_urls = dict()\n",
        "        self.annotation_urls = dict()\n",
        "        for object_id, item_dict in enumerate(data_dict['data']):\n",
        "            self.image_urls[object_id] = item_dict['image_url'].replace('\\\\', '/')\n",
        "            self.annotation_urls[object_id] = item_dict['annotation_url'].replace('\\\\', '/')\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # load images and annotations\n",
        "        image_url = self.image_urls[idx]\n",
        "        annotation_url = self.annotation_urls[idx]\n",
        "        annotation_dict = utils.load_json(annotation_url)\n",
        "        image = Image.open(image_url)\n",
        "        image_height, image_width = image.size\n",
        "        num_objects = len(annotation_dict['shapes'])\n",
        "        labels, boxes, polygons = list(), list(), list()\n",
        "        target = dict()\n",
        "\n",
        "        for idx, shape in enumerate(annotation_dict['shapes']):\n",
        "            label = self.classes.index(shape['label'].upper())\n",
        "            polygon = [(int(x), int(y)) for x, y in shape['points']]\n",
        "            labels.append(label)\n",
        "            polygons.append(polygon)\n",
        "\n",
        "        masks_array = np.zeros((image_width, image_height))\n",
        "        masks_array = utils.draw_polygons_on_image_array(masks_array, polygons)\n",
        "        object_ids = np.unique(masks_array)[1:]  # Remove index for background\n",
        "        mask_arrays = masks_array == object_ids[:, None, None]\n",
        "\n",
        "        for mask_array in mask_arrays:\n",
        "            box = utils.compute_box_from_mask_array(mask_array)\n",
        "            boxes.append(box)\n",
        "\n",
        "        labels_tensor = torch.from_numpy(np.array(labels))\n",
        "        boxes_tensor = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        masks_tensor = torch.as_tensor(mask_arrays, dtype=torch.uint8)\n",
        "\n",
        "        image_id = torch.tensor([idx])\n",
        "        area = (boxes_tensor[:, 3] - boxes_tensor[:, 1]) * (boxes_tensor[:, 2] - boxes_tensor[:, 0])\n",
        "\n",
        "        is_crowd = torch.zeros((num_objects,), dtype=torch.int64)\n",
        "\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = is_crowd\n",
        "        target[\"labels\"] = labels_tensor\n",
        "        target[\"boxes\"] = boxes_tensor\n",
        "        target[\"masks\"] = masks_tensor\n",
        "\n",
        "        if self.transforms is not None: image_tensor, target = self.transforms(image, target)\n",
        "\n",
        "        return image_tensor, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_urls)"
      ],
      "metadata": {
        "id": "TBCF28lLotx1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import modules.detection.scripts.transforms as detection_transforms\n",
        "\n",
        "def get_transform(train):\n",
        "    transforms = []\n",
        "    # converts the image, a PIL image, into a PyTorch Tensor\n",
        "    transforms.append(detection_transforms.ToTensor())\n",
        "    ### feel free to add additional transforms here below\n",
        "\n",
        "    return detection_transforms.Compose(transforms)"
      ],
      "metadata": {
        "id": "0U4vkYuepSLF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detection_data_path = os.path.join('datasets', 'detection')\n",
        "# training dataset\n",
        "detection_train_set = DetectionDataset(detection_data_path, mode='train', transforms=get_transform(True))\n",
        "# validation dataset\n",
        "detection_valid_set = DetectionDataset(detection_data_path, mode='valid', transforms=get_transform(True))\n",
        "#testing dataset\n",
        "detection_test_set = DetectionDataset(detection_data_path, mode='test', transforms=get_transform(False))\n",
        "\n",
        "detection_classes = detection_train_set.classes\n",
        "num_detection_classes  = len(detection_classes)"
      ],
      "metadata": {
        "id": "jRFZMrSBpl2_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of classes: {}\\nClasses: {}'.format(num_detection_classes, detection_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wEbquVLpuEm",
        "outputId": "2ab10474-5d9f-429d-a4c4-cdefdb760806"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 2\n",
            "Classes: ['BACKGROUND', 'STUDENT_ID']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id = 0\n",
        "obj_id = None\n",
        "obj_label = ''\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "\n",
        "image_tensor, targets = detection_train_set[id]\n",
        "\n",
        "boxes = targets['boxes'] # retrieve bounding boxes\n",
        "image = utils.tensorToPIL(image_tensor)\n",
        "image_array = np.array(image)\n",
        "\n",
        "for box in boxes :\n",
        "  cv2.rectangle(image_array, (box[0],box[1]), (box[2],box[3]), (255,0,0), 2) # draw bounding boxes\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 1, xticks=[], yticks=[])\n",
        "plt.imshow(Image.fromarray(image_array))\n",
        "ax.set_title('Image')\n",
        "\n",
        "if obj_id is not None:\n",
        "    mask_tensor = targets['masks'][obj_id] # retrieve bounding masks\n",
        "    obj_label_idx = targets['labels'][[obj_id]].item() # retrieve bounding labels\n",
        "    obj_label = ': ' + detection_classes[obj_label_idx]\n",
        "else :\n",
        "    mask_tensor = torch.zeros_like(image_tensor)\n",
        "    for _mask_tensor in targets['masks'] : mask_tensor += _mask_tensor # paste mask for every object\n",
        "\n",
        "ax1 = fig.add_subplot(1, 2, 2, xticks=[], yticks=[])\n",
        "ax1.set_title('Segentation Mask' + obj_label)\n",
        "mask = utils.tensorToPIL(mask_tensor)\n",
        "plt.imshow(mask)\n",
        "None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "d94V76w9pzAN",
        "outputId": "bae7554a-b404-4f78-b191-c6b7f402931e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.8.0) :-1: error: (-5:Bad argument) in function 'rectangle'\n> Overload resolution failed:\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-a283dd399bd9>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mboxes\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# draw bounding boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) :-1: error: (-5:Bad argument) in function 'rectangle'\n> Overload resolution failed:\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "\n",
        "def get_instance_segmentation_model(num_classes, state_dict=None):\n",
        "    # load an instance segmentation model pre-trained on COCO\n",
        "    detection_model = torchvision.models.detection.maskrcnn_resnet50_fpn(progress=True, pretrained=True)\n",
        "    # get the number of input features for the classifier\n",
        "    in_features = detection_model.roi_heads.box_predictor.cls_score.in_features\n",
        "    ### FINETUNE pret-trained model\n",
        "    # replace the pre-trained head with a new one\n",
        "    detection_model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    # now get the number of input features for the mask classifier\n",
        "    in_features_mask = detection_model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    hidden_layer = 256\n",
        "    # and replace the mask predictor with a new one\n",
        "    detection_model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer,  num_classes)\n",
        "    if state_dict is not None: detection_model.load_state_dict(state_dict)\n",
        "    return detection_model"
      ],
      "metadata": {
        "id": "zeBLCdbDqf-h"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select hardware use for computations\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "load_detection_checkpoint = True\n",
        "save_detection_checkpoint = False\n",
        "\n",
        "detection_checkpoint_path = os.path.join('checkpoints', 'detection_mask_rcnn_resnet50.pth.tar')\n",
        "\n",
        "'''\n",
        "Do not edit the lines below\n",
        "'''\n",
        "\n",
        "if load_detection_checkpoint :\n",
        "  detection_checkpoint = torch.load(detection_checkpoint_path, map_location=device) if os.path.exists(detection_checkpoint_path) else None\n",
        "  detection_model_state_dict = detection_checkpoint['model_state_dict'] if not detection_checkpoint == None else None\n",
        "  detection_optimizer_state_dict = detection_checkpoint['optimizer_state_dict'] if not detection_checkpoint == None else None\n",
        "else :\n",
        "  detection_checkpoint, detection_model_state_dict, detection_optimizer_state_dict = None, None, None\n",
        "\n",
        "if not save_detection_checkpoint : detection_checkpoint_path = None\n",
        "# initialize detection model using the state dictionary from checkpoint\n",
        "detection_model = get_instance_segmentation_model(num_detection_classes, state_dict = detection_model_state_dict)\n",
        "\n",
        "if detection_checkpoint == None : print('No checkpoint loaded ! Loaded pre-trained model instead...')\n",
        "else :\n",
        "  print('Loaded model from checkpoint...')\n",
        "  utils.checkpoint_summary(detection_checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRRQYwGVqiIR",
        "outputId": "ba7beac5-5e25-412c-94d2-4ff4151efbd5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n",
            "100%|██████████| 170M/170M [00:01<00:00, 131MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No checkpoint loaded ! Loaded pre-trained model instead...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import modules.detection.scripts.utils as script_utils\n",
        "\n",
        "# data loader for training\n",
        "detection_train_loader = torch.utils.data.DataLoader(\n",
        "    detection_train_set, batch_size=6, shuffle=True, num_workers=4,\n",
        "    collate_fn=script_utils.collate_fn)\n",
        "\n",
        "# data loader for validation\n",
        "detection_valid_loader = torch.utils.data.DataLoader(\n",
        "    detection_valid_set, batch_size=2, shuffle=False, num_workers=2,\n",
        "    collate_fn=script_utils.collate_fn)\n",
        "\n",
        "# data loader for testing\n",
        "detection_test_loader = torch.utils.data.DataLoader(\n",
        "    detection_test_set, batch_size=2, shuffle=False, num_workers=0,\n",
        "    collate_fn=script_utils.collate_fn)\n",
        "\n",
        "# defining orientation data loaders dictionary\n",
        "detection_loaders = {\n",
        "    'train' : detection_train_loader,\n",
        "    'valid' : detection_valid_loader,\n",
        "    'test' : detection_test_loader,\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdYAuywmqma_",
        "outputId": "2a3c83fc-521d-4e0d-8a21-0054aa05a89b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# activate gradients calculation for unfreezed parameters\n",
        "detection_params = [p for p in detection_model.parameters() if p.requires_grad]\n",
        "# initialize training optimizer with learning rate, momentum and weight decay\n",
        "detection_optimizer = torch.optim.SGD(detection_params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "# define learning rate schelduler to gradually decay learning rate\n",
        "detection_lr_scheduler = torch.optim.lr_scheduler.StepLR(detection_optimizer, step_size=10, gamma=0.95)\n",
        "\n",
        "# load optimizer state dictionary from checkpoint if available\n",
        "if detection_optimizer_state_dict is None:  print('No checkpoint loaded ! Optimizer not loaded from checkpoint...')\n",
        "else:\n",
        "    detection_optimizer.load_state_dict(detection_optimizer_state_dict)\n",
        "    print('Loaded optizer from checkpoint...')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVKXsc3Mq6nA",
        "outputId": "bad1f3d1-3d44-436e-faa3-cd344da3debb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No checkpoint loaded ! Optimizer not loaded from checkpoint...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y apex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6clCBm5seFv",
        "outputId": "6807d485-5355-461b-b99a-b3ea1996f873"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping apex as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import training and evaluation functions\n",
        "from modules.detection.scripts.engine import train_one_epoch, evaluate\n",
        "\n",
        "def train_detection_model(model, num_epochs=10, loaders=None, checkpoint=None, checkpoint_path=None,\n",
        "                optimizer= None, lr_scheduler= None, print_freq=1, device=torch.device('cuda')):\n",
        "\n",
        "    if checkpoint is None: start_epoch = 1\n",
        "    else:\n",
        "        print('Resuming training from checkpoint...')\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "\n",
        "    model.to(device) # Move model to cpu or cuda device\n",
        "\n",
        "    time_train = time.time()\n",
        "    for epoch in range(start_epoch, num_epochs + 1):\n",
        "        time_epoch = time.time()\n",
        "        # train for one epoch, printing every '{print_freq}' iterations\n",
        "        train_one_epoch(model, optimizer, loaders['train'], device, epoch, print_freq=print_freq)\n",
        "        # update the learning rate\n",
        "        lr_scheduler.step()\n",
        "        # evaluate model on the validation dataset\n",
        "        # evaluate(model, loaders['valid'], device=device)\n",
        "\n",
        "        time_epoch_elapsed = time.time() - time_epoch\n",
        "        time_train_elapsed = time.time() - time_train\n",
        "        print('Epoch: {}\\tEpoch Time: {:.0f}m {:.0f}s\\tElapsed Time: {:.0f}m {:.0f}s'.format(\n",
        "             epoch, time_epoch_elapsed // 60, time_epoch_elapsed % 60,\n",
        "             time_train_elapsed // 60, time_train_elapsed % 60))\n",
        "\n",
        "        # Save checkpoint after every epoch if checkpoint_path is given\n",
        "        if not checkpoint_path == None:\n",
        "            utils.save_checkpoint(model.state_dict(), optimizer.state_dict(), epoch, checkpoint_path)\n",
        "\n",
        "    return model # retun trained model"
      ],
      "metadata": {
        "id": "9BX16jYZrY_g"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "source": [
        "# start training the detection model for 20 epochs\n",
        "detection_model = train_detection_model(detection_model, num_epochs= 20, loaders= detection_loaders,\n",
        "                        checkpoint= detection_checkpoint, checkpoint_path= detection_checkpoint_path,\n",
        "                        optimizer= detection_optimizer, lr_scheduler= detection_lr_scheduler,\n",
        "                        print_freq=10, device= device)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz-7nw98r8Q8",
        "outputId": "e74e0d4d-d52a-4527-9796-722d8d0cdc3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1]  [ 0/20]  eta: 1:14:40  lr: 0.005000  loss: 4.8553 (4.8553)  loss_classifier: 0.5772 (0.5772)  loss_box_reg: 0.1257 (0.1257)  loss_mask: 4.1330 (4.1330)  loss_objectness: 0.0058 (0.0058)  loss_rpn_box_reg: 0.0135 (0.0135)  time: 224.0260  data: 1.5236\n",
            "Epoch: [1]  [10/20]  eta: 0:35:55  lr: 0.005000  loss: 0.9627 (1.5756)  loss_classifier: 0.0807 (0.1431)  loss_box_reg: 0.1325 (0.1379)  loss_mask: 0.6950 (1.2705)  loss_objectness: 0.0127 (0.0129)  loss_rpn_box_reg: 0.0107 (0.0112)  time: 215.5683  data: 0.1525\n"
          ]
        }
      ]
    }
  ]
}